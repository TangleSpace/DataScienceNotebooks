{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Could we have got there quicker?\n",
    "## The power of laziness"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We are now onto the 3rd look at this horrible dataset and whilst we have a better answer than just gun hoe and we have some better support for some of our assumptions and eye ball test bullshit, did we still mow straight over the obvious and justify it as using the eye ball test and some more fancy transformation of the data?\n",
    "\n",
    "If you're like me, I may have bailed out before I got this far with this discussion, however, for anyone still waiting for the punch line and having the mental endurance to last this long, your reward is absa-freakin luttly we could have got a solid answer, compeltely justifed with much less work and I would say, an even more warm and fuzzy feeling solution as well as better insight and explainability.\n",
    "\n",
    "Shit! that sounds like gold flakes will start raining down or something, but the point is, there is atleast one tool I use to cut through the bullshit quickly and in the spirit of back of the envelope calculations, provides expediance and surprisingly accuracte and easy to explain results.\n",
    "\n",
    "Ok, enough woffling, here we go....."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Some imports to get us active\n",
    "from utils.tools import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data shape: (1767, 5)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>total_actualtonnes</th>\n",
       "      <th>plannedreceivals</th>\n",
       "      <th>totalactualcycles</th>\n",
       "      <th>Totalplannedcycles</th>\n",
       "      <th>delta</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>date</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2016-01-01</th>\n",
       "      <td>501223</td>\n",
       "      <td>542116</td>\n",
       "      <td>60</td>\n",
       "      <td>64</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-02</th>\n",
       "      <td>414366</td>\n",
       "      <td>471262</td>\n",
       "      <td>50</td>\n",
       "      <td>56</td>\n",
       "      <td>-86857.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-03</th>\n",
       "      <td>356261</td>\n",
       "      <td>401661</td>\n",
       "      <td>44</td>\n",
       "      <td>49</td>\n",
       "      <td>-58105.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-04</th>\n",
       "      <td>459762</td>\n",
       "      <td>463961</td>\n",
       "      <td>56</td>\n",
       "      <td>56</td>\n",
       "      <td>103501.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2016-01-05</th>\n",
       "      <td>344504</td>\n",
       "      <td>462463</td>\n",
       "      <td>43</td>\n",
       "      <td>57</td>\n",
       "      <td>-115258.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            total_actualtonnes  plannedreceivals  totalactualcycles  \\\n",
       "date                                                                  \n",
       "2016-01-01              501223            542116                 60   \n",
       "2016-01-02              414366            471262                 50   \n",
       "2016-01-03              356261            401661                 44   \n",
       "2016-01-04              459762            463961                 56   \n",
       "2016-01-05              344504            462463                 43   \n",
       "\n",
       "            Totalplannedcycles     delta  \n",
       "date                                      \n",
       "2016-01-01                  64       0.0  \n",
       "2016-01-02                  56  -86857.0  \n",
       "2016-01-03                  49  -58105.0  \n",
       "2016-01-04                  56  103501.0  \n",
       "2016-01-05                  57 -115258.0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dfInbound_tonnes = pd.read_pickle('data/inbound_tonnes2010010120201101.pkl')\n",
    "print('Data shape: {}'.format(dfInbound_tonnes.shape))\n",
    "dfInbound_tonnes.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The short and sweet answer is, we only need to ask one question before we start anything with time series data, what type of evolution over time does the data series have? Now I'm not taking a crap on your expectation and the lead up being deflated by this seemingly dull and slightly obtuse question, but this is it, does the data typically move upwards/downwards, flip back and forth or is on a [random walk](https://en.wikipedia.org/wiki/Random_walk). Knowing with information will allow us to quickly discount alot of analysis and modelling candidates and provide a guide on the fastest (and lazyest way to get the job done).\n",
    "\n",
    "One measure to rule them all ![one measure](img/one-ring.jpg)\n",
    "\n",
    "[The Hurst exponent](https://en.wikipedia.org/wiki/Hurst_exponent), in a nutshell, we calculate the Hurst exponent for a time series and compare it to the ranges below. This provides our slice through the details to know what we are dealing with. \n",
    "> $H = 0.5$ — Brownian motion <br>\n",
    "> $0.5 < H < 1.0$ — persistent behavior <br>\n",
    "> $0 < H < 0.5$ — anti-persistent behavior\n",
    "\n",
    "\n",
    "I can hear the screamers now, oh but it doesn't do this and there is this analysis and you're full of crap and my mum said you're a troglodyte and so on. Feel free to have a nap to recover from this trauma then, but you will find if you use this method upfront, you can get back to your crisps or fags or vodka quicker, than if you don't."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hurst exponent ch: 0.5622493572029746, Coeff: 1.1156813449545677\n",
      "\n",
      "Hurst exponent wn->rw: 0.5622493572029746, Coeff: 1.1156813449545677\n",
      "\n",
      "Hurst exponent rw: 0.1919741808613579, Coeff: 2.1795255871803927\n",
      "\n",
      "Hurst exponent pr: 0.8067781712826502, Coeff: 0.5040377725099195\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Let's run the data set through the function and see what we get\n",
    "\n",
    "H,c,data = compute_Hc(dfInbound_tonnes.total_actualtonnes, kind='change', simplified=False)\n",
    "print('Hurst exponent ch: {0}, Coeff: {1}\\n'.format(H,c))\n",
    "\n",
    "H,c,data = compute_Hc(dfInbound_tonnes.total_actualtonnes-dfInbound_tonnes.total_actualtonnes.mean(), kind='change', simplified=False)\n",
    "print('Hurst exponent wn->rw: {0}, Coeff: {1}\\n'.format(H,c))\n",
    "\n",
    "H,c,data = compute_Hc(dfInbound_tonnes.total_actualtonnes, kind='random_walk', simplified=False)\n",
    "print('Hurst exponent rw: {0}, Coeff: {1}\\n'.format(H,c))\n",
    "\n",
    "H,c,data = compute_Hc(dfInbound_tonnes.total_actualtonnes.cumsum(), kind='price', simplified=False)\n",
    "print('Hurst exponent pr: {0}, Coeff: {1}\\n'.format(H,c))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A quick explination of the 3 different values and the kind parameter....blah blah blah\n",
    "\n",
    "\n",
    "Comparing this with the range, we see for change, there is some persistant behaviour, not much tough. For the comparison to random walk, we see little association and a low value less than 0.5 indicates the data tends to revert to the mean rather than trending. The price version indicates we do see clear trending in the cummulative summation of the data, which correlates with the conclusion from the change value. After a while you'll get a feel for how much information these values contain and how much direct insight into the nature of the time series can be inferred from this one metric, albeit with 3 favours.\n",
    "\n",
    "The conclusion is that the data tends to revert to the mean most of the time, with some trend that appears to be in a consistant direction. From this, we can immediately rule out models that include cyclic patterns and strongly trending approaches, as there is trend present, just not very much."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.2 64-bit",
   "language": "python",
   "name": "python38264bitbc2c1b10dd7d4e95b9291e4e22348160"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
